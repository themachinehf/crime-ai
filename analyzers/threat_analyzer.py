"""
Crime AI - å¨èƒåˆ†æå¼•æ“
åŸºäºæ–‡æœ¬æƒ…æ„Ÿå’Œå…³é”®è¯è¿›è¡ŒçŠ¯ç½ªé¢„æµ‹
"""

import re
from datetime import datetime
from typing import Dict, List, Tuple
from dataclasses import dataclass

@dataclass
class ThreatLevel:
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class ThreatIndicator:
    keyword: str
    score: int
    category: str

class ThreatAnalyzer:
    """å¨èƒåˆ†æå™¨ - æ£€æµ‹æ½œåœ¨çŠ¯ç½ªä¿¡å·"""
    
    # æš´åŠ›ç›¸å…³å…³é”®è¯åŠå…¶å¨èƒåˆ†æ•°
    VIOLENCE_KEYWORDS = {
        # ä¸¥é‡æš´åŠ›
        "kill": 90,
        "murder": 95,
        "shoot": 85,
        "attack": 80,
        "massacre": 100,
        "terrorist": 95,
        "bomb": 90,
        "explosion": 85,
        "rape": 95,
        "stab": 85,
        
        # å¨èƒè¡¨è¾¾
        "threaten": 70,
        "hurt": 65,
        "destroy": 70,
        "revenge": 75,
        "payback": 70,
        "eliminate": 80,
        "wipe out": 85,
        "end it all": 90,
        "going to kill": 95,
        "want them dead": 95,
        
        # æ­¦å™¨ç›¸å…³
        "gun": 60,
        "knife": 55,
        "weapon": 65,
        "arsenal": 75,
        "ammunition": 65,
    }
    
    # å¨èƒç±»å‹åˆ†ç±»
    THREAT_CATEGORIES = {
        "physical_violence": ["kill", "murder", "shoot", "attack", "stab", "hurt"],
        "terrorism": ["terrorist", "bomb", "explosion", "massacre"],
        "self_harm": ["end it all", "suicide", "want to die", "give up"],
        "harassment": ["threaten", "harass", "stalk", "bullying"],
        "property_crime": ["steal", "rob", "burglary", "vandalism"],
    }
    
    def __init__(self):
        self.threat_keywords = self.VIOLENCE_KEYWORDS.copy()
    
    def analyze_text(self, text: str) -> Dict:
        """åˆ†ææ–‡æœ¬ï¼Œè¿”å›å¨èƒè¯„ä¼°"""
        text_lower = text.lower()
        
        # æ£€æµ‹å¨èƒå…³é”®è¯
        found_threats = []
        total_score = 0
        
        for keyword, score in self.threat_keywords.items():
            if keyword in text_lower:
                found_threats.append({
                    "keyword": keyword,
                    "score": score,
                    "category": self._categorize_keyword(keyword)
                })
                total_score += score
        
        # æ£€æµ‹æ¨¡å¼
        patterns = self._detect_patterns(text_lower)
        
        # è®¡ç®—æœ€ç»ˆå¨èƒåˆ†æ•°
        base_score = min(total_score, 100)
        pattern_bonus = sum(p["score"] for p in patterns)
        final_score = min(base_score + pattern_bonus, 100)
        
        # ç¡®å®šå¨èƒç­‰çº§
        threat_level = self._calculate_threat_level(final_score)
        
        return {
            "text_preview": text[:100] + "..." if len(text) > 100 else text,
            "threat_score": final_score,
            "threat_level": threat_level,
            "found_threats": found_threats,
            "detected_patterns": patterns,
            "analyzed_at": datetime.now().isoformat()
        }
    
    def _categorize_keyword(self, keyword: str) -> str:
        """åˆ†ç±»å…³é”®è¯"""
        for category, keywords in self.THREAT_CATEGORIES.items():
            if keyword in keywords:
                return category
        return "general_threat"
    
    def _detect_patterns(self, text: str) -> List[Dict]:
        """æ£€æµ‹å¯ç–‘æ¨¡å¼"""
        patterns = []
        
        # ç´§è¿«æ€§æ¨¡å¼
        urgent_patterns = [
            r"right now",
            r"tonight",
            r"today.*going to",
            r"tomorrow.*will",
            r"this weekend",
        ]
        
        for pattern in urgent_patterns:
            if re.search(pattern, text):
                patterns.append({
                    "type": "urgency",
                    "description": "è¡¨è¾¾ç´§è¿«è¡ŒåŠ¨æ„å›¾",
                    "score": 15
                })
        
        # å—å®³è€…æŒ‡å®šæ¨¡å¼
        victim_patterns = [
            r"my (boss|colleague|teacher|classmate|neighbor|ex)",
            r"that (guy|girl|person|man|woman)",
            r"they.*deserve",
        ]
        
        for pattern in victim_patterns:
            if re.search(pattern, text):
                patterns.append({
                    "type": "targeted",
                    "description": "æŒ‡å®šå…·ä½“ç›®æ ‡",
                    "score": 20
                })
        
        # è®¡åˆ’æ¨¡å¼
        planning_patterns = [
            r"going to buy",
            r"just ordered",
            r"already have",
            r"waiting for",
        ]
        
        for pattern in planning_patterns:
            if re.search(pattern, text):
                patterns.append({
                    "type": "planning",
                    "description": "æ˜¾ç¤ºå‡†å¤‡è¡Œä¸º",
                    "score": 25
                })
        
        return patterns
    
    def _calculate_threat_level(self, score: int) -> str:
        """è®¡ç®—å¨èƒç­‰çº§"""
        if score >= 80:
            return ThreatLevel.CRITICAL
        elif score >= 60:
            return ThreatLevel.HIGH
        elif score >= 40:
            return ThreatLevel.MEDIUM
        else:
            return ThreatLevel.LOW
    
    def calculate_crime_probability(self, threats: List[Dict], 
                                     location: str = None,
                                     time_factor: float = 1.0) -> Dict:
        """è®¡ç®—çŠ¯ç½ªæ¦‚ç‡ï¼ˆTHE MACHINE æ ¸å¿ƒç®—æ³•ï¼‰"""
        
        if not threats:
            return {
                "probability": 0,
                "risk_level": "minimal",
                "prediction": "æœªæ£€æµ‹åˆ°å¨èƒä¿¡å·"
            }
        
        # æå–é«˜å±å¨èƒ
        high_risk_threats = [t for t in threats if t["threat_level"] in ["high", "critical"]]
        
        # åŸºç¡€æ¦‚ç‡
        base_prob = len(high_risk_threats) * 15 + sum(
            t["threat_score"] for t in high_risk_threats
        ) * 0.1
        
        # ä½ç½®å› ç´ 
        location_risk = 1.0
        high_risk_areas = ["school", "government", "mall", "public"]
        for area in high_risk_areas:
            if area in (location or "").lower():
                location_risk = 1.3
                break
        
        # æ—¶é—´å› ç´ ï¼ˆæ·±å¤œ/å‡Œæ™¨æ›´é«˜é£é™©ï¼‰
        hour = datetime.now().hour
        time_factor = 1.5 if hour < 6 or hour > 23 else 1.0
        
        # è®¡ç®—æœ€ç»ˆæ¦‚ç‡
        final_probability = min(base_prob * location_risk * time_factor, 100)
        
        # ç”Ÿæˆé¢„æµ‹
        prediction = self._generate_prediction(final_probability, high_risk_threats)
        
        return {
            "probability": round(final_probability, 1),
            "risk_level": self._get_risk_label(final_probability),
            "prediction": prediction,
            "threat_count": len(high_risk_threats),
            "time_factor": time_factor,
            "location_factor": location_risk,
            "analyzed_at": datetime.now().isoformat()
        }
    
    def _generate_prediction(self, probability: float, threats: List[Dict]) -> str:
        """ç”Ÿæˆé¢„æµ‹æè¿°"""
        if probability >= 80:
            return "âš ï¸ é«˜æ¦‚ç‡çŠ¯ç½ªé£é™©ï¼Œå»ºè®®ç«‹å³ä»‹å…¥"
        elif probability >= 60:
            return "ğŸ”´ ä¸­é«˜é£é™©ï¼Œå»ºè®®å¯†åˆ‡å…³æ³¨"
        elif probability >= 40:
            return "ğŸŸ¡ ä¸­ç­‰é£é™©ï¼Œä¿æŒç›‘æ§"
        elif probability >= 20:
            return "ğŸŸ¢ ä½é£é™©ï¼Œç»§ç»­è§‚å¯Ÿ"
        else:
            return "âœ… é£é™©æä½"
    
    def _get_risk_label(self, probability: float) -> str:
        """è·å–é£é™©æ ‡ç­¾"""
        if probability >= 80:
            return "extreme"
        elif probability >= 60:
            return "high"
        elif probability >= 40:
            return "moderate"
        elif probability >= 20:
            return "low"
        else:
            return "minimal"


# æµ‹è¯•
if __name__ == "__main__":
    analyzer = ThreatAnalyzer()
    
    test_texts = [
        "I'm so angry at my boss, I want to kill him",
        "Going to buy a gun tomorrow",
        "I hate my ex, she deserves to suffer",
        "This weekend I'm going to bomb the school",
        "Just had a bad day at work",
    ]
    
    print("=== Crime AI Threat Analysis ===\n")
    
    for text in test_texts:
        result = analyzer.analyze_text(text)
        print(f"Text: {text}")
        print(f"Level: {result['threat_level']} | Score: {result['threat_score']}")
        print(f"Threats: {[t['keyword'] for t in result['found_threats']]}")
        print()
