"""
Crime AI - ç¤¾äº¤åª’ä½“ç›‘æŽ§å™¨
ç›‘æŽ§ Twitter/X, Reddit ç­‰å¹³å°çš„å¨èƒä¿¡å·
"""

import os
import time
import json
from datetime import datetime
from typing import List, Dict, Optional
from analyzers.threat_analyzer import ThreatAnalyzer

class SocialMonitor:
    """ç¤¾äº¤åª’ä½“å¨èƒä¿¡å·ç›‘æŽ§å™¨"""
    
    def __init__(self):
        self.analyzer = ThreatAnalyzer()
        self.threat_log = []
        
        # ç›‘æŽ§é…ç½®
        self.config = {
            "twitter": {
                "enabled": False,  # éœ€è¦ API Key
                "keywords": ["kill", "bomb", "attack", "shoot", "murder", "terrorist"],
                "locations": ["nyc", "los angeles", "chicago", "houston", "phoenix"]
            },
            "reddit": {
                "enabled": True,
                "subreddits": ["r/legaladvice", "r/relationships", "r/confessions", 
                              "r/UnresolvedMysteries", "r/TrueCrime"],
                "keywords": ["threaten", "hurt", "revenge", "planning"]
            }
        }
    
    def check_text(self, text: str, source: str = "unknown") -> Optional[Dict]:
        """æ£€æŸ¥å•æ¡æ–‡æœ¬"""
        analysis = self.analyzer.analyze_text(text)
        
        if analysis["threat_level"] in ["high", "critical"]:
            threat = {
                "source": source,
                "text": text,
                "analysis": analysis,
                "detected_at": datetime.now().isoformat()
            }
            self.threat_log.append(threat)
            return threat
        
        return None
    
    def scan_reddit(self, subreddit: str, limit: int = 10) -> List[Dict]:
        """æ‰«æ Reddit å¸–å­ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # å®žé™…å®žçŽ°éœ€è¦ praw åº“
        # è¿™é‡Œè¿”å›žæ¨¡æ‹Ÿæ•°æ®ç”¨äºŽæµ‹è¯•
        
        sample_posts = [
            {
                "title": "My boss is making my life hell, I want to hurt him",
                "body": "I've been thinking about revenge lately",
                "score": 45
            },
            {
                "title": "Had a terrible fight with my ex",
                "body": "She deserves everything bad to happen to her",
                "score": 38
            },
            {
                "title": "Just need to vent about work today",
                "body": "Stressful day but I'll be fine",
                "score": 5
            }
        ]
        
        threats = []
        for post in sample_posts[:limit]:
            full_text = f"{post['title']} {post['body']}"
            threat = self.check_text(full_text, f"reddit/{subreddit}")
            if threat:
                threat["post_score"] = post["score"]
                threats.append(threat)
        
        return threats
    
    def get_threat_statistics(self) -> Dict:
        """èŽ·å–å¨èƒç»Ÿè®¡"""
        if not self.threat_log:
            return {
                "total_threats": 0,
                "by_level": {},
                "by_source": {},
                "last_updated": datetime.now().isoformat()
            }
        
        by_level = {}
        by_source = {}
        
        for threat in self.threat_log:
            level = threat["analysis"]["threat_level"]
            source = threat["source"]
            
            by_level[level] = by_level.get(level, 0) + 1
            by_source[source] = by_source.get(source, 0) + 1
        
        return {
            "total_threats": len(self.threat_log),
            "by_level": by_level,
            "by_source": by_source,
            "last_updated": datetime.now().isoformat()
        }
    
    def export_threat_report(self) -> Dict:
        """å¯¼å‡ºå¨èƒæŠ¥å‘Š"""
        return {
            "report_time": datetime.now().isoformat(),
            "statistics": self.get_threat_statistics(),
            "recent_threats": self.threat_log[-10:] if self.threat_log else [],
            "prediction": self._generate_threat_prediction()
        }
    
    def _generate_threat_prediction(self) -> Dict:
        """ç”Ÿæˆå¨èƒé¢„æµ‹"""
        stats = self.get_threat_statistics()
        
        if stats["total_threats"] == 0:
            return {
                "citywide_risk": "minimal",
                "predicted_crimes": 0,
                "hotspots": [],
                "confidence": "high"
            }
        
        # ç®€åŒ–çš„é¢„æµ‹ç®—æ³•
        high_risk_count = stats["by_level"].get("high", 0) + stats["by_level"].get("critical", 0)
        
        return {
            "citywide_risk": "elevated" if high_risk_count > 0 else "low",
            "predicted_crimes": high_risk_count * 2,
            "hotspots": list(stats["by_source"].keys())[:3],
            "confidence": "medium"
        }


# æµ‹è¯•
if __name__ == "__main__":
    monitor = SocialMonitor()
    
    print("=== Crime AI Social Monitor ===\n")
    
    # æµ‹è¯•æ£€æµ‹
    test_texts = [
        ("I want to kill my teacher", "twitter"),
        ("Going to bomb the mall this weekend", "twitter"),
        ("My coworker is annoying but whatever", "slack"),
        ("She deserves to die", "reddit")
    ]
    
    for text, source in test_texts:
        result = monitor.check_text(text, source)
        if result:
            print(f"ðŸš¨ THREAT DETECTED!")
            print(f"   Source: {source}")
            print(f"   Level: {result['analysis']['threat_level']}")
            print()
    
    # ç»Ÿè®¡
    stats = monitor.get_threat_statistics()
    print(f"Total threats: {stats['total_threats']}")
    print(f"By level: {stats['by_level']}")
